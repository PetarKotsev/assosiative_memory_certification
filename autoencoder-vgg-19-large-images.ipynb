{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Imports \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nimport torch.nn as nn\nfrom tqdm.autonotebook import tqdm, trange\n\nimport sys\nimport matplotlib.pyplot as plt\nfrom torchvision import models\n\nimport imagenet_autoencoder_utils as utils\nplt.rcParams['figure.figsize'] = [15, 10]\n\nfrom IPython import display\ndisplay.set_matplotlib_formats('svg')\n\n# use GPU\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nprint (device)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-18T21:23:35.231425Z","iopub.execute_input":"2022-08-18T21:23:35.231720Z","iopub.status.idle":"2022-08-18T21:23:37.508501Z","shell.execute_reply.started":"2022-08-18T21:23:35.231657Z","shell.execute_reply":"2022-08-18T21:23:37.507424Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def loss_function(W, x, recons_x, h, lam):\n    \"\"\"Compute the Contractive AutoEncoder Loss\n    Evalutes the CAE loss, which is composed as the summation of a Mean\n    Squared Error and the weighted l2-norm of the Jacobian of the hidden\n    units with respect to the inputs.\n    See reference below for an in-depth discussion:\n      #1: http://wiseodd.github.io/techblog/2016/12/05/contractive-autoencoder\n    Args:\n        `W` (FloatTensor): (N_hidden x N), where N_hidden and N are the\n          dimensions of the hidden units and input respectively.\n        `x` (Variable): the input to the network, with dims (N_batch x N)\n        recons_x (Variable): the reconstruction of the input, with dims\n          N_batch x N.\n        `h` (Variable): the hidden units of the network, with dims\n          batch_size x N_hidden\n        `lam` (float): the weight given to the jacobian regulariser term\n    Returns:\n        Variable: the (scalar) CAE loss\n    \"\"\"\n    mse = mse_loss(recons_x, x)\n    # Since: W is shape of N_hidden x N. So, we do not need to transpose it as\n    # opposed to #1\n    dh = h * (1 - h) # Hadamard product produces size N_batch x N_hidden\n    # Sum through the input dimension to improve efficiency, as suggested in #1\n    w_sum = torch.sum(Variable(W)**2, dim=1)\n    # unsqueeze to avoid issues with torch.mv\n    w_sum = w_sum.unsqueeze(1) # shape N_hidden x 1\n    contractive_loss = torch.sum(torch.mm(dh**2, w_sum), 0)\n    return mse + contractive_loss.mul_(lam)\n\n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get data\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom PIL import Image\nimport os\n\nDATA_PATH_TRAIN = '../input/imagenetmini-1000/imagenet-mini/train'\nDATA_PATH_VAL = '../input/imagenetmini-1000/imagenet-mini/val'\n\n## devide the image by 255\ntransform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\nbatch_size = 32\n\ntrain_dataset = datasets.ImageFolder(DATA_PATH_TRAIN, transform=transform)\nval_dataset = datasets.ImageFolder(DATA_PATH_VAL, transform=transform)\n\ntrain_set_size = len(train_dataset) - len(train_dataset)%batch_size\nval_set_size = len(val_dataset) - len(val_dataset)%batch_size\n\nprint(len(train_dataset))\nprint(len(val_dataset))\n\n# Shorten the dataset\ntrain_indecies = torch.arange(train_set_size)\nval_indecies = torch.arange(val_set_size)\n\ntrain_set = Subset(train_dataset, train_indecies)\nval_set = Subset(val_dataset, val_indecies)\n\ntrain_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True, pin_memory=True, drop_last=False)\nval_dataloader = DataLoader(val_set, batch_size=batch_size, shuffle=True, pin_memory=True, drop_last=False)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-18T21:23:37.510881Z","iopub.execute_input":"2022-08-18T21:23:37.512019Z","iopub.status.idle":"2022-08-18T21:23:51.819684Z","shell.execute_reply.started":"2022-08-18T21:23:37.511979Z","shell.execute_reply":"2022-08-18T21:23:51.818612Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# loading the classes\nif not os.path.exists(\"/kaggle/working/imagenet_classes.txt\"):\n    !wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\nif not os.path.exists(\"/kaggle/working/map_clsloc.txt\"):\n    !wget https://gist.githubusercontent.com/aaronpolhamus/964a4411c0906315deb9f4a3723aac57/raw/aa66dd9dbf6b56649fa3fab83659b2acbf3cbfd1/map_clsloc.txt    \n    \nwith open(\"/kaggle/working/imagenet_classes.txt\", \"r\") as f:\n    classes = [s.strip() for s in f.readlines()]","metadata":{"execution":{"iopub.status.busy":"2022-08-18T21:23:51.821249Z","iopub.execute_input":"2022-08-18T21:23:51.821596Z","iopub.status.idle":"2022-08-18T21:23:54.549467Z","shell.execute_reply.started":"2022-08-18T21:23:51.821561Z","shell.execute_reply":"2022-08-18T21:23:54.548182Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class VggSplit(nn.Module):\n    \"\"\"This is the model definition of vgg-19 but split just before the avg. pool layer\"\"\"\n    def __init__(self, vgg):\n        super(VggSplit, self).__init__()\n        # with batch normalization\n        self.encoder = []\n        self.encoder.append(nn.Sequential(*list(vgg.features.children())[:6]))\n        self.encoder.append(nn.Sequential(*list(vgg.features.children())[6:13]))\n        self.encoder.append(nn.Sequential(*list(vgg.features.children())[13:26]))\n        self.encoder.append(nn.Sequential(*list(vgg.features.children())[26:39]))\n        self.encoder.append(nn.Sequential(*list(vgg.features.children())[39:-1]))\n        self.lastMax = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n\n        self.avg_pool = vgg.avgpool\n        self.classifier = nn.Sequential(*list(vgg.classifier.children()))\n\n    def forward(self, x):\n        inter_outputs = []\n        for encoder_layer in self.encoder:\n            x = encoder_layer(x)\n            inter_outputs.append(x)\n            \n        encoder_out = self.lastMax(x)\n        avg_pool_out = self.avg_pool(encoder_out)\n        flat = torch.flatten(avg_pool_out, 1)\n        classifier_out = self.classifier(flat)\n        return encoder_out, classifier_out, inter_outputs","metadata":{"execution":{"iopub.status.busy":"2022-08-18T21:23:54.552942Z","iopub.execute_input":"2022-08-18T21:23:54.553302Z","iopub.status.idle":"2022-08-18T21:23:54.565946Z","shell.execute_reply.started":"2022-08-18T21:23:54.553274Z","shell.execute_reply":"2022-08-18T21:23:54.564427Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def plotValidation(images, model, classes):\n    test_fig, test_axis = plt.subplots(2,5)\n    \n    images = images.to(device)\n    out, class_out = model(images)\n    \n    out = utils.unNormalize(out, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    images = utils.unNormalize(images, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    probabilities = torch.nn.functional.softmax(class_out, dim=0)\n\n    out = out.to('cpu')\n    out = torch.permute(out, (0,2,3,1))\n    images = images.to('cpu')\n    images = torch.permute(images, (0,2,3,1))\n    probabilities = probabilities.to('cpu')\n\n    top_class_out = torch.topk(probabilities, 1)\n    indexes = top_class_out.indices.detach().numpy()\n    values = top_class_out.values.detach().numpy()\n\n    for inx, image in enumerate(images):\n        test_axis[0,inx].imshow(image.detach().squeeze().numpy())\n        test_axis[0,inx].set_title(str(classes[indexes[inx,0]]))\n        test_axis[1,inx].imshow(out[inx].detach().squeeze().numpy())\n        test_axis[1,inx].set_title('{:.2f}'.format(criterion(image, out[inx])))\n\n    test_fig.tight_layout()\n    test_fig.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-18T21:23:54.568052Z","iopub.execute_input":"2022-08-18T21:23:54.569057Z","iopub.status.idle":"2022-08-18T21:23:54.581751Z","shell.execute_reply.started":"2022-08-18T21:23:54.569020Z","shell.execute_reply":"2022-08-18T21:23:54.580375Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# download pretrained model\nvgg = models.vgg19_bn(pretrained=True, progress=True)\nvgg = vgg.to(device)\n\n# val_images = torch.unsqueeze()\n# val_images = torch.cat(val_images)\n# print(tuple(val_dataloader)[:10])","metadata":{"execution":{"iopub.status.busy":"2022-08-18T21:23:54.583755Z","iopub.execute_input":"2022-08-18T21:23:54.584465Z","iopub.status.idle":"2022-08-18T21:24:50.513637Z","shell.execute_reply.started":"2022-08-18T21:23:54.584429Z","shell.execute_reply":"2022-08-18T21:24:50.512646Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"model_test_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=True, pin_memory=True)\n\ndef val_VGG(model, val_dataloader):\n    acc = utils.AverageMeter()\n    for X_val,Y_val in val_dataloader:\n        X_val = X_val.to(device)\n        Y_val = Y_val.to(device)\n\n        with torch.no_grad():\n            classification = model(X_val)\n\n        top_class_out = torch.topk(classification, 5)\n        top_class_out = torch.squeeze(top_class_out.indices)\n\n        # convert to float\n        Y_val = Y_val.type(torch.float)\n        top_class_out = top_class_out.type(torch.float)\n        curr_acc = int(Y_val in top_class_out)\n        acc.update(curr_acc)\n    return acc\n\nres = val_VGG(vgg, model_test_dataloader)\nprint(res.avg)","metadata":{"execution":{"iopub.status.busy":"2022-08-18T21:25:11.335058Z","iopub.execute_input":"2022-08-18T21:25:11.335773Z","iopub.status.idle":"2022-08-18T21:26:37.869471Z","shell.execute_reply.started":"2022-08-18T21:25:11.335737Z","shell.execute_reply":"2022-08-18T21:26:37.867559Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"vgg = VggSplit(vgg)\nvgg = vgg.to(device)\nvgg.eval()","metadata":{"execution":{"iopub.status.busy":"2022-08-18T21:29:57.766545Z","iopub.execute_input":"2022-08-18T21:29:57.767118Z","iopub.status.idle":"2022-08-18T21:29:57.776816Z","shell.execute_reply.started":"2022-08-18T21:29:57.767083Z","shell.execute_reply":"2022-08-18T21:29:57.775771Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"class DecoderBN(nn.Module):\n    \"\"\"Decoder with batch normalization\"\"\"\n    def __init__(self):\n        super(DecoderBN, self).__init__()\n        self.dec0 = nn.Sequential(\n            nn.Upsample(scale_factor=2, mode='nearest'),\n        )\n        self.dec1 = nn.Sequential(\n            nn.ReLU(),\n            nn.BatchNorm2d(1024),\n            nn.Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1),  padding_mode='reflect', bias=False),\n\n            nn.ReLU(),\n            nn.BatchNorm2d(512),\n            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1),  padding_mode='reflect', bias=False ),\n        \n            \n            nn.ReLU(),\n            nn.BatchNorm2d(512),\n            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1),  padding_mode='reflect', bias=False ),\n\n\n            nn.ReLU(),\n            nn.BatchNorm2d(512),\n            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1),  padding_mode='reflect', bias=False ),\n\n\n            nn.Upsample(scale_factor=2, mode='nearest'),\n        )\n        self.dec2 = nn.Sequential(\n            nn.ReLU(),\n            nn.BatchNorm2d(1024),\n            nn.Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1),  padding_mode='reflect', bias=False ),\n\n            nn.ReLU(),\n            nn.BatchNorm2d(512),\n            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1),  padding_mode='reflect', bias=False ),\n\n            nn.ReLU(),\n            nn.BatchNorm2d(512),\n            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1),  padding_mode='reflect', bias=False ),\n            # from here on is the old version\n            nn.ReLU(),\n            nn.BatchNorm2d(512),\n            nn.Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode='reflect', bias=False ),\n\n            nn.Upsample(scale_factor=2, mode='nearest'),\n        )\n        self.dec3 = nn.Sequential(\n\n            nn.ReLU(),\n            nn.BatchNorm2d(512),\n            nn.Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode='reflect', bias=False),\n\n            nn.ReLU(),\n            nn.BatchNorm2d(256),\n            nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode='reflect', bias=False),\n            \n            nn.ReLU(),\n            nn.BatchNorm2d(256),\n            nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode='reflect', bias=False),\n\n            nn.ReLU(),\n            nn.BatchNorm2d(256),\n            nn.Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode='reflect', bias=False),\n\n            nn.Upsample(scale_factor=2, mode='nearest'),\n        )\n        self.dec4 = nn.Sequential(\n            nn.ReLU(),\n            nn.BatchNorm2d(256),\n            nn.Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode='reflect', bias=False),\n            \n            nn.ReLU(),\n            nn.BatchNorm2d(128),\n            nn.Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode='reflect', bias=False),\n\n            nn.Upsample(scale_factor=2, mode='nearest'),\n        )\n        self.dec5 = nn.Sequential(\n            nn.ReLU(),\n            nn.BatchNorm2d(128),\n            nn.Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode='reflect', bias=False),\n            nn.ReLU(),\n            nn.BatchNorm2d(64),\n            nn.Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode='reflect', bias=False),\n        )\n\n    def forward(self, x):\n        with torch.no_grad():\n            x, classifier, encoder_layers = vgg(x)\n        # flip the encoder_layers list\n        encoder_layers = encoder_layers[::-1]\n        x = self.dec0(x)\n        x = torch.cat((x, encoder_layers[0]), 1)\n        x = self.dec1(x)\n        x = torch.cat((x, encoder_layers[1]), 1)\n        x = self.dec2(x)\n        x = torch.cat((x, encoder_layers[2]), 1)\n        x = self.dec3(x)\n        x = torch.cat((x, encoder_layers[3]), 1)\n        x = self.dec4(x)\n        x = torch.cat((x, encoder_layers[4]), 1)\n        x = self.dec5(x)\n        return x, classifier","metadata":{"execution":{"iopub.status.busy":"2022-08-18T21:30:17.010362Z","iopub.execute_input":"2022-08-18T21:30:17.010787Z","iopub.status.idle":"2022-08-18T21:30:17.035190Z","shell.execute_reply.started":"2022-08-18T21:30:17.010754Z","shell.execute_reply":"2022-08-18T21:30:17.034033Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# instantiate model\nmodel = DecoderBN()\n# transfer the model to the GPU\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-08-18T21:30:20.079123Z","iopub.execute_input":"2022-08-18T21:30:20.080098Z","iopub.status.idle":"2022-08-18T21:30:20.369442Z","shell.execute_reply.started":"2022-08-18T21:30:20.080061Z","shell.execute_reply":"2022-08-18T21:30:20.368378Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\n\ndef train(model, epochs = 10, lr = 0.01, criterion = nn.MSELoss(), optimizer='adam',name='', set_size=10000):\n\n    min_loss = 99999\n    \n    if (optimizer=='adam'):\n        optimizer = optim.Adam(model.parameters(), lr=lr)\n    elif (optimizer=='sgd'):\n        optimizer = optim.SGD(model.parameters(), lr=lr)\n    else:\n        raise Exception('Optimizer not recognized!')\n\n    loss_history = np.zeros(epochs)\n    val_history = np.zeros(epochs)\n    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n#     scheduler = torch.optim.lr_scheduler.LinearLR(optimizer)\n#     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n\n\n    for epoch in tqdm(range(epochs)):\n        model.train()\n        epoch_loss = utils.AverageMeter()\n        t = tqdm(total=set_size, desc='|_ Mini-batch '+ str(epoch), unit='eval')\n        for X_train,_ in train_dataloader:\n            # Move to device\n            X_train = X_train.to(device)\n            \n            # Get prediction\n            out, _ = model(X_train)\n\n            # Get the loss\n            curr_loss = criterion(X_train, out)\n            epoch_loss.update(curr_loss.item(), batch_size)\n\n            # Make the adjustments\n            optimizer.zero_grad()\n            curr_loss.backward()\n            optimizer.step()\n            t.set_postfix(lr=optimizer.param_groups[0][\"lr\"], epoch_loss=epoch_loss.avg)\n            t.update(batch_size)\n        t.close()\n        # print/record loss\n        loss_history[epoch] = epoch_loss.avg\n        scheduler.step()\n        \n        # eval\n        val_loss = utils.AverageMeter()\n        model.eval()\n        \n        for X_val,_ in val_dataloader:\n            X_val = X_val.to(device)\n            \n            with torch.no_grad():\n                res, _ = model(X_val)\n            \n            curr_loss = criterion(X_val, res)\n            val_loss.update(curr_loss.item(), batch_size)\n        \n#         scheduler.step(val_loss.avg)\n        val_history[epoch] = val_loss.avg\n        \n        if val_loss.avg < min_loss:\n            # Save model\n            print('Model saved: '+ str(val_loss.avg))\n            torch.save(model.state_dict(), '/kaggle/working/test'+'-c_'+name+'.pth')\n            min_loss = val_loss.avg\n            \n        print(val_loss.avg)\n        \n    return loss_history, val_history","metadata":{"execution":{"iopub.status.busy":"2022-08-18T21:30:22.877191Z","iopub.execute_input":"2022-08-18T21:30:22.877741Z","iopub.status.idle":"2022-08-18T21:30:22.891642Z","shell.execute_reply.started":"2022-08-18T21:30:22.877704Z","shell.execute_reply":"2022-08-18T21:30:22.890310Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\n\ndef contractive_train(model, epochs = 10, lr = 0.01, criterion = nn.MSELoss(), optimizer='sgd',name='', set_size=10000):\n\n    min_loss = 99999\n    \n    if (optimizer=='adam'):\n        optimizer = optim.Adam(model.parameters(), lr=lr)\n    elif (optimizer=='sgd'):\n        optimizer = optim.SGD(model.parameters(), lr=lr)\n    else:\n        raise Exception('Optimizer not recognized!')\n\n    loss_history = np.zeros(epochs)\n    val_history = np.zeros(epochs)\n    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n#     scheduler = torch.optim.lr_scheduler.LinearLR(optimizer)\n#     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n\n\n    for epoch in tqdm(range(epochs)):\n        model.train()\n        epoch_loss = utils.AverageMeter()\n        t = tqdm(total=set_size, desc='|_ Mini-batch '+ str(epoch), unit='eval')\n        for X_train,_ in train_dataloader:\n            # Move to device\n            X_train = X_train.to(device)\n            \n            # Get prediction\n            out, _ = model(X_train)\n\n            # Get the loss\n            W = model.state_dict()['.weight']\n            curr_loss = loss_function(out, X_train,)\n            epoch_loss.update(curr_loss.item(), batch_size)\n\n            # Make the adjustments\n            optimizer.zero_grad()\n            curr_loss.backward()\n            optimizer.step()\n            t.set_postfix(lr=optimizer.param_groups[0][\"lr\"], epoch_loss=epoch_loss.avg)\n            t.update(batch_size)\n        t.close()\n        # print/record loss\n        loss_history[epoch] = epoch_loss.avg\n        scheduler.step()\n        \n        # eval\n        val_loss = utils.AverageMeter()\n        model.eval()\n        \n        for X_val,_ in val_dataloader:\n            X_val = X_val.to(device)\n            \n            with torch.no_grad():\n                res, _ = model(X_val)\n            \n            curr_loss = criterion(X_val, res)\n            val_loss.update(curr_loss.item(), batch_size)\n        \n#         scheduler.step(val_loss.avg)\n        val_history[epoch] = val_loss.avg\n        \n        if val_loss.avg < min_loss:\n            # Save model\n            print('Model saved: '+ str(val_loss.avg))\n            torch.save(model.state_dict(), '/kaggle/working/test'+'-c_'+name+'.pth')\n            min_loss = val_loss.avg\n            \n        print(val_loss.avg)\n        \n    return loss_history, val_history","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loss_history = train(criterion = nn.CrossEntropyLoss())\ncriterion = loss_function() # nn.MSELoss()\nloss_history, val_history = train(model, epochs=12, criterion = criterion, optimizer='sgd', name='MSE', set_size=train_set_size) ","metadata":{"execution":{"iopub.status.busy":"2022-08-18T21:30:26.340021Z","iopub.execute_input":"2022-08-18T21:30:26.340695Z","iopub.status.idle":"2022-08-18T21:59:13.619777Z","shell.execute_reply.started":"2022-08-18T21:30:26.340658Z","shell.execute_reply":"2022-08-18T21:59:13.618347Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"\ndef plotLosses(losses, val_history):\n\n    ax1 = plt.subplot(211, yscale='log')\n    ax1.plot(losses)\n    ax1.set_title('Training error')\n\n    ax2 = plt.subplot(212, yscale='log')\n    ax2.plot(val_history)\n    ax2.set_title('Validation error')\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-18T21:25:09.691729Z","iopub.status.idle":"2022-08-18T21:25:09.692212Z","shell.execute_reply.started":"2022-08-18T21:25:09.691952Z","shell.execute_reply":"2022-08-18T21:25:09.691974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plotLosses(loss_history, val_history)","metadata":{"execution":{"iopub.status.busy":"2022-08-18T21:25:09.693889Z","iopub.status.idle":"2022-08-18T21:25:09.694414Z","shell.execute_reply.started":"2022-08-18T21:25:09.694175Z","shell.execute_reply":"2022-08-18T21:25:09.694199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), '/kaggle/working/test'+'-c_final.pth')\ntorch.save(loss_history, '/kaggle/working/test_loss_his.pth')\ntorch.save(val_history, '/kaggle/working/test_val_his.pth')\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2022-08-18T21:59:20.616051Z","iopub.execute_input":"2022-08-18T21:59:20.616666Z","iopub.status.idle":"2022-08-18T21:59:20.802635Z","shell.execute_reply.started":"2022-08-18T21:59:20.616630Z","shell.execute_reply":"2022-08-18T21:59:20.801212Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def plotValidation(images, img_categs, model, classes):\n    test_fig, test_axis = plt.subplots(2,5)\n    \n    images = images.to(device)\n    with torch.no_grad():\n        out, class_out = model(images)\n    \n    out = utils.unNormalize(out, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    images = utils.unNormalize(images, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    probabilities = torch.nn.functional.softmax(class_out, dim=0)\n\n    out = out.to('cpu')\n    out = torch.permute(out, (0,2,3,1))\n    images = images.to('cpu')\n    images = torch.permute(images, (0,2,3,1))\n    probabilities = probabilities.to('cpu')\n\n    top_class_out = torch.topk(probabilities, 1)\n    indexes = top_class_out.indices.detach().numpy()\n    values = top_class_out.values.detach().numpy()\n\n    for inx, image in enumerate(images):\n        test_axis[0,inx].imshow(image.detach().squeeze().numpy())\n        test_axis[0,inx].set_title(str(classes[img_categs[inx]]))\n        test_axis[1,inx].imshow(out[inx].detach().squeeze().numpy())\n        test_axis[1,inx].set_title(str(classes[indexes[inx,0]])+\" [\"+str('{:.2f}'.format(criterion(image, out[inx]))) +\"]\")\n\n    test_fig.tight_layout()\n    test_fig.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-18T21:59:24.302504Z","iopub.execute_input":"2022-08-18T21:59:24.302868Z","iopub.status.idle":"2022-08-18T21:59:24.315986Z","shell.execute_reply.started":"2022-08-18T21:59:24.302838Z","shell.execute_reply":"2022-08-18T21:59:24.314616Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"model = DecoderBN()\nmodel = model.to(device)\nmodel.load_state_dict(torch.load('/kaggle/working/test-c_MSE.pth'))\nmodel.eval()\n\nimages,img_cat = next(iter(val_dataloader))\ntest_images = images[:5]\n\nplotValidation(test_images,img_cat, model, classes)","metadata":{"execution":{"iopub.status.busy":"2022-08-18T21:59:26.606400Z","iopub.execute_input":"2022-08-18T21:59:26.606800Z","iopub.status.idle":"2022-08-18T21:59:29.107327Z","shell.execute_reply.started":"2022-08-18T21:59:26.606768Z","shell.execute_reply":"2022-08-18T21:59:29.106490Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"class BoolMeter:\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.num_succ = 0\n        self.num_fail = 0\n        self.count = 0\n        self.values = []\n\n    def update(self, value):\n        if value:\n            self.num_succ += 1\n        else:\n            self.num_fail += 1\n        self.count += 1\n        self.values.append(value) \n\n\ndef validate_dataset(model, val_dataloader, rec_criterion, set_size):\n    cat_acc = BoolMeter()\n    rec_err = utils.AverageMeter()\n    t = tqdm(total=set_size, desc='VAL ', unit='eval')\n    for X_val,Y_val in val_dataloader:\n        X_val = X_val.to(device)\n        Y_val = Y_val.to(device)\n\n        with torch.no_grad():\n            rec_out, classification = model(X_val)\n\n        rec_err.update(rec_criterion(rec_out, X_val).detach().item(), X_val.size()[0])\n        \n        top_class_out = torch.topk(classification, 5)\n        top_class_out = torch.squeeze(top_class_out.indices)\n\n        # convert to float\n        Y_val = Y_val.type(torch.float)\n        top_class_out = top_class_out.type(torch.float)\n        \n        if X_val.size()[0] == 1:\n            curr_acc = (Y_val in top_class_out)\n        cat_acc.update(curr_acc)\n        t.update(X_val.size()[0])\n    t.close()\n    return rec_err, cat_acc","metadata":{"execution":{"iopub.status.busy":"2022-08-18T21:59:48.596212Z","iopub.execute_input":"2022-08-18T21:59:48.596977Z","iopub.status.idle":"2022-08-18T21:59:48.607771Z","shell.execute_reply.started":"2022-08-18T21:59:48.596937Z","shell.execute_reply":"2022-08-18T21:59:48.606666Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"rec_err, cat_acc = validate_dataset(model, model_test_dataloader, criterion, 3923)","metadata":{"execution":{"iopub.status.busy":"2022-08-19T00:06:14.515227Z","iopub.execute_input":"2022-08-19T00:06:14.516270Z","iopub.status.idle":"2022-08-19T00:08:00.835089Z","shell.execute_reply.started":"2022-08-19T00:06:14.516221Z","shell.execute_reply":"2022-08-19T00:08:00.833942Z"},"trusted":true},"execution_count":166,"outputs":[]},{"cell_type":"code","source":"print(cat_acc.num_succ, cat_acc.num_fail)\nplt.scatter(rec_err.values, cat_acc.values)\nplt.xlabel('Reconstruction error (MSELoss)')\nplt.ylabel('Categorisation acc (%)')\nplt.title('Error correlation')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-19T00:08:04.934550Z","iopub.execute_input":"2022-08-19T00:08:04.934909Z","iopub.status.idle":"2022-08-19T00:08:05.287745Z","shell.execute_reply.started":"2022-08-19T00:08:04.934880Z","shell.execute_reply":"2022-08-19T00:08:05.283451Z"},"trusted":true},"execution_count":167,"outputs":[]},{"cell_type":"code","source":"def plot_barchart(buckets, succ_buckets, fail_buckets, bar_labels):\n    width = 0.001       # the width of the bars: can also be len(x) sequence\n\n    fig, ax = plt.subplots()\n\n    ax.bar(buckets, succ_buckets, width, label='Success')\n    fails = ax.bar(buckets, fail_buckets, width, bottom=succ_buckets,\n           label='Fail')\n\n    ax.bar_label(fails, bar_labels)\n    \n    ax.set_ylabel('Categorisation')\n    ax.set_xlabel('Reconstruction error (MSE)')\n    ax.set_xlim([-0.001, 0.04])\n    ax.set_title('Categorisation success relative to reconstruction error')\n    ax.legend()\n\n    plt.show()\n    \n    plt.bar(buckets, bar_labels, width, label='Succ ratio')\n    plt.title('Categorisation accuracy in relation to reconstruction acc.')\n    plt.ylabel('Accuracy (%)')\n    plt.xlabel('Reconstruction error (MSE)')\n    \n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-08-19T00:11:43.717649Z","iopub.execute_input":"2022-08-19T00:11:43.718018Z","iopub.status.idle":"2022-08-19T00:11:43.726615Z","shell.execute_reply.started":"2022-08-19T00:11:43.717980Z","shell.execute_reply":"2022-08-19T00:11:43.725431Z"},"trusted":true},"execution_count":174,"outputs":[]},{"cell_type":"code","source":"rec_err_vals_rounded = torch.round(torch.tensor(rec_err.values), decimals=3).numpy()\ncat_acc_vals = cat_acc.values\nunique = np.unique(rec_err_vals_rounded)\nsuccs, fails, ratios, ratios_scaled = [], [], [], []\nfor val in unique:\n    occ = np.extract(rec_err_vals_rounded==val, cat_acc_vals)\n    succs.append(np.count_nonzero(occ==True))\n    fails.append(np.count_nonzero(occ==False))\n    ratios.append(round(np.count_nonzero(occ==True)/len(occ), 2))\n    ratios_scaled.append(round(np.count_nonzero(occ==True)*(len(occ)/len(rec_err_vals_rounded))/len(occ), 2))\n    \n\nplot_barchart(unique, succs, fails, ratios)\nplot_barchart(unique, succs, fails, ratios_scaled)","metadata":{"execution":{"iopub.status.busy":"2022-08-19T00:11:22.850823Z","iopub.execute_input":"2022-08-19T00:11:22.851210Z","iopub.status.idle":"2022-08-19T00:11:25.112931Z","shell.execute_reply.started":"2022-08-19T00:11:22.851177Z","shell.execute_reply":"2022-08-19T00:11:25.112049Z"},"trusted":true},"execution_count":173,"outputs":[]},{"cell_type":"code","source":"recriation_imgs = test_images\nprint(recriation_imgs.size())\nerrs = []\n\nerr = 9999\ncounter = 0\nrecriation_imgs = recriation_imgs.to(device)\nwhile err > 0.001:\n    with torch.no_grad():\n        rec_out, _ = model(recriation_imgs)\n\n    err = criterion(rec_out, recriation_imgs).detach().item()\n    errs.append(err)\n    print(err, end=\"\\r\")\n    recriation_imgs = rec_out\n    counter += 1\n    if counter >= 1000:\n        break","metadata":{"execution":{"iopub.status.busy":"2022-08-19T00:04:58.569168Z","iopub.execute_input":"2022-08-19T00:04:58.569963Z","iopub.status.idle":"2022-08-19T00:05:47.871314Z","shell.execute_reply.started":"2022-08-19T00:04:58.569927Z","shell.execute_reply":"2022-08-19T00:05:47.869798Z"},"trusted":true},"execution_count":164,"outputs":[]},{"cell_type":"code","source":"test_fig, test_axis = plt.subplots(2,5)\n    \nrecriation_imgs = utils.unNormalize(recriation_imgs, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\ntest_images = utils.unNormalize(test_images, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n\nrecriation_imgs = recriation_imgs.to('cpu')\nrecriation_imgs = torch.permute(recriation_imgs, (0,2,3,1))\ntest_images = test_images.to('cpu')\ntest_images = torch.permute(test_images, (0,2,3,1))    \n    \nfor inx, image in enumerate(test_images):\n    test_axis[0,inx].imshow(image.detach().squeeze().numpy())\n#     test_axis[0,inx].set_title(str(classes[img_categs[inx]]))\n    test_axis[1,inx].imshow(recriation_imgs[inx].detach().squeeze().numpy())\n#     test_axis[1,inx].set_title(str(classes[indexes[inx,0]])+\" [\"+str('{:.2f}'.format(criterion(image, out[inx]))) +\"]\")\n\ntest_fig.tight_layout()\ntest_fig.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-19T00:05:50.652832Z","iopub.execute_input":"2022-08-19T00:05:50.653855Z","iopub.status.idle":"2022-08-19T00:05:52.289685Z","shell.execute_reply.started":"2022-08-19T00:05:50.653816Z","shell.execute_reply":"2022-08-19T00:05:52.285426Z"},"trusted":true},"execution_count":165,"outputs":[]}]}